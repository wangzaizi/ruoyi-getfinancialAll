
# 中国地级行政区划财政报告爬虫

这是一个用于爬取中华人民共和国334个地级行政区划（地级市、地区、自治州、盟等）财政决算报告的爬虫程序。

## 功能特点

- 自动搜索334个地级行政区划的政府网站
- 智能识别和下载财政决算报告（PDF、Word、Excel等格式）
- 支持断点续传，自动保存进度
- 详细的日志记录和错误处理
- 并发控制和请求延迟，避免过度访问

## 目录结构

```
.
├── spider.py          # 主爬虫程序
├── config.py          # 配置文件
├── cities_data.py     # 334个地级行政区划数据
├── requirements.txt   # Python依赖包
├── README.md          # 说明文档
├── downloads/         # 下载的文件目录（按城市分类）
├── logs/             # 日志文件目录
└── data/             # 数据文件目录（进度、摘要等）
```

## 安装依赖

```bash
pip install -r requirements.txt
```

## 使用方法

### 测试模式（推荐先测试）

在运行完整爬取之前，建议先使用测试模式验证功能：

```bash
python test_spider.py
```

或者使用交互式启动脚本：

```bash
python run.py
# 选择选项 1 进入测试模式
```

测试模式会爬取少量城市（默认：赣州市、北京市、上海市、杭州市、深圳市），可以用来验证：
- 网络连接是否正常
- 政府网站是否可以访问
- 文件下载功能是否正常

### 完整模式

运行完整爬取所有334个城市：

```bash
python spider.py
```

或者使用交互式启动脚本：

```bash
python run.py
# 选择选项 2 进入完整模式
```

程序会自动：
1. 遍历334个地级行政区划
2. 搜索每个城市的政府网站
3. 查找2024年财政决算报告相关页面
4. 下载PDF等格式的报告文件
5. 保存到 `downloads/[城市名]/` 目录下

### 配置说明

可以在 `config.py` 中修改以下配置：

- `TARGET_YEAR`: 目标年份（默认：2024）
- `CONCURRENT_REQUESTS`: 并发请求数（默认：5）
- `REQUEST_DELAY`: 请求延迟秒数（默认：2秒）
- `TIMEOUT`: 请求超时时间（默认：30秒）
- `MAX_RETRIES`: 最大重试次数（默认：3次）
- `SEARCH_KEYWORDS`: 搜索关键词列表
- `TARGET_FILE_TYPES`: 目标文件类型

### 查看进度

程序运行过程中会自动保存进度到 `data/progress.json`，可以随时查看。

最终结果会保存到 `data/summary.json`，包含：
- 总城市数
- 成功爬取的城市数
- 失败的城市数
- 总下载文件数
- 每个城市的详细结果

## 技术实现思路

### 核心设计理念

本项目采用智能化的网站搜索策略，而非简单粗暴的URL拼接，确保能够适应不同政府网站的结构差异。

### 关键技术点

#### 1. 政府网站搜索策略
- **已知网站映射**：为常用城市（如北京、上海、赣州等）预设了已知的政府网站URL，优先使用
- **百度搜索辅助**：当直接访问失败时，通过百度搜索查找政府网站
- **多域名尝试**：尝试多种常见的政府网站域名格式（如 `www.{城市名}.gov.cn`）

#### 2. 原生表单提交与参数捕获
- **智能表单识别**：自动识别页面中的搜索表单（`<form>`标签）
- **字段提取**：提取表单中的所有字段，包括：
  - 所有 `input` 字段（包括隐藏字段）
  - 所有 `select` 下拉框及其默认值
  - 所有 `textarea` 文本域
- **原生提交测试**：先使用测试关键词进行真实的表单提交，捕获所有实际使用的参数
- **参数模板复用**：使用捕获的参数模板进行后续搜索，确保参数格式正确（如 `pageNum`, `siteCode`, `timeStamp` 等）

#### 3. 双方法提交策略
- **GET和POST同时尝试**：无论成功失败，都会同时使用GET和POST两种方法提交搜索
- **结果合并**：合并两种方法的所有搜索结果，提高成功率
- **参数模板支持**：两种方法都支持使用捕获的参数模板

#### 4. 智能结果过滤
- **关键词匹配**：结果必须同时包含搜索关键词（如"决算"）和目标年份（如"2024"）
- **非连续匹配**：不要求关键词和年份连续出现或特定顺序
  - ✅ "2024年决算报告" - 匹配
  - ✅ "决算2024报告" - 匹配
  - ✅ "2024年政府决算" - 匹配
  - ❌ "决算报告"（无年份）- 不匹配
  - ❌ "2024报告"（无关键词）- 不匹配

#### 5. 分页自动遍历
- **自动识别分页**：通过多种方式识别下一页链接：
  - 文本内容（"下一页"、"下页"、"next"等）
  - CSS类名和ID（`class="next"`, `id="page-next"`等）
  - 页码链接（识别数字页码）
  - URL参数（`pageNum`, `page`, `p`等）
- **完整遍历**：自动遍历所有分页，直到没有下一页为止
- **去重保护**：避免重复处理同一页面
- **安全限制**：最多遍历100页，防止无限循环

#### 6. 全面链接搜索
- **不跳过任何内容**：无论是否找到特定的结果容器，都会搜索页面中的所有链接
- **多文本来源**：从链接标题、URL、周围文本等多个来源提取信息进行匹配
- **去重机制**：确保每个链接只处理一次

#### 7. 文件下载优化
- **扩展名优先**：如果URL包含文件扩展名（如 `.xlsx`, `.pdf`），即使Content-Type是HTML也会尝试下载
  - 处理服务器错误设置Content-Type的情况
  - 例如：`https://example.com/file.xlsx` 返回HTML，但仍会下载
- **文件验证**：下载后验证文件大小，确保不为空
- **重试机制**：失败后自动重试（最多3次），递增延迟

### 工作流程

```
1. 搜索政府网站
   ├─ 检查已知网站映射
   ├─ 尝试标准域名格式
   └─ 百度搜索辅助查找

2. 查找搜索表单
   ├─ 在首页查找
   └─ 如未找到，尝试常见搜索页面（/search, /search.html等）

3. 原生表单提交测试
   ├─ 提取所有表单字段
   ├─ 使用测试关键词提交（GET和POST两种方法）
   └─ 捕获成功提交的参数模板

4. 执行实际搜索
   ├─ 使用参数模板 + 实际搜索关键词
   ├─ GET方法提交
   └─ POST方法提交（无论GET是否成功）

5. 解析搜索结果
   ├─ 遍历所有分页（自动识别下一页）
   ├─ 搜索页面中的所有链接
   └─ 过滤：必须同时包含"决算"和"2024"

6. 下载文件
   ├─ 提取PDF/Word/Excel链接
   ├─ 验证文件扩展名（即使Content-Type是HTML也下载）
   └─ 保存到 downloads/[城市名]/ 目录
```

### 特殊处理

#### 参数模板示例
某些政府网站的搜索需要复杂的参数结构，例如：
```
searchWord=决算
column=全部
pageSize=10
pageNum=0
siteCode=3607000056
startTime=2024-01-01 00:00:00
endTime=2024-12-31 23:59:59
timeStamp=1
```

程序会：
1. 通过原生提交捕获这些参数
2. 在后续搜索中只替换 `searchWord`，保留其他参数
3. 自动更新时间相关字段（如 `startTime`, `endTime`, `timeStamp`）

#### 分页处理示例
对于使用 `pageNum` 参数的分页：
- 第1页：`pageNum=0` 或 `pageNum=1`
- 第2页：`pageNum=1` 或 `pageNum=2`
- 程序会自动识别并递增页码，直到没有更多结果

## 报告类型

程序会搜索以下类型的财政报告：

- **一般公共预算决算报告**
- **政府性基金预算决算报告**
- **国有资本经营预算决算报告**
- **社会保险基金预算决算报告**
- **地方政府债务报告**
- **决算公开目录**

## 注意事项

1. **网络环境**：确保网络连接正常，某些政府网站可能需要特定的网络环境访问

2. **访问频率**：程序已设置请求延迟，避免对目标网站造成过大压力

3. **网站结构**：不同城市的政府网站结构可能不同，程序会尝试多种搜索策略

4. **数据完整性**：由于网站结构和内容差异，可能无法获取所有城市的完整报告

5. **法律合规**：请确保爬取行为符合相关法律法规和网站使用条款

## 故障排查

### 如果某个城市下载失败：

1. 检查日志文件 `logs/spider_YYYYMMDD.log`
2. 查看 `data/summary.json` 中该城市的错误信息
3. 可以手动访问该城市的政府网站，检查报告是否已发布

### 常见问题：

- **未找到政府网站**：某些城市可能使用非标准的域名结构
- **未找到财政报告**：报告可能在其他栏目或使用不同的命名方式
- **下载失败**：可能是网络问题或文件链接失效

## 技术支持

如遇问题，请查看日志文件获取详细信息。

## 许可证

本项目仅供学习和研究使用。

# ruoyi-getfinancialAll

## 沟通过程与改动摘要

为提升在不同城市政府网站上的“财政决算公开”检索与下载效果，我们在多轮沟通中做了以下迭代（时间顺序）：

1) 搜索策略由“固定路径”改为“按站点实际内容检索”  
- 原逻辑依赖若干常见路径（如 `/czj/`, `/zfxxgk/` 等）。  
- 新逻辑从首页出发，优先收集“公开/信息公开/政务公开/政府信息公开/财政信息公开/财政公开”等栏目链接，再在这些栏目页内遍历列表并分页解析。

2) 增加财政局域名变体（以深圳为例）  
- 在 `search_government_website` 中加入 `{abbr}fb.{abbr}.gov.cn` 等组合（如 `szfb.sz.gov.cn`），并保留原有 `czj.*`、`czt.*`、`*cz.gov.cn` 规则。

3) 一度引入“站内检索”和检索日志  
- 为部分站点识别搜索表单与常见端点（/search, /s, /so 等），统一用关键词“决算”，若表单/端点支持时间参数则自动限制至目标年份（如 2024）。  
- 打印每次检索的 URL、参数与命中数，提升可观测性。

4) 统一且严格的过滤条件（所有方式都生效）  
- 无论是栏目遍历、分页解析、iframe/直链附件，均要求文本/URL同时满足：  
  - 含“决算”  
  - 含目标年份（默认 2024）  
  - 含层级/地域指示（“本级”/“本市”/“xx市”）  
  - 排除“部门/单位/街道/镇/乡”等关键词  
- 修复了页面命中但附件名为 2023 等情况仍被下载的问题，现在附件本身也必须匹配上述规则。

5) 放弃“站内检索”，保留“公开栏目遍历 + 有限深度暴力遍历”  
- 根据需求，最终移除了站内检索步骤。当前流程：
  - 收集公开相关栏目链接 → 在栏目页内进行分页解析与过滤；  
  - 若仍无结果，对公开栏目进行域内、有限深度（可配置）的 BFS 暴力遍历，并继续应用同一过滤规则。

6) 关键实现位置（便于查阅）  
- `spider.py`  
  - `FinanceReportSpider.search_government_website`：财政局网站发现（含拼音与域名变体）。  
  - `FinanceReportSpider.search_finance_reports`：公开栏目收集、分页解析、必要时的有限深度暴力遍历。  
  - `FinanceReportSpider.parse_search_results`：分页与链接提取。  
  - `FinanceReportSpider.matches_keywords`：统一过滤规则（年份/层级/关键词/排除项）。  
  - `FinanceReportSpider.extract_pdf_links`：仅返回通过过滤的附件链接（含 iframe 场景）。

7) 使用建议  
- 若要更换年份，请在 `config.py` 修改 `TARGET_YEAR`（默认 2024），所有过滤与检索将随之生效。  
- 如需扩大/收紧暴力遍历的深度与页数上限，可在 `search_finance_reports` 中调整相应参数（`depth_limit`, `max_pages`）。
